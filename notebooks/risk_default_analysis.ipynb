{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4220ce2",
   "metadata": {},
   "source": [
    "# Home Credit Default Risk "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c08fae",
   "metadata": {},
   "source": [
    "## About Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d586b6",
   "metadata": {},
   "source": [
    "- application_{train|test}.csv\n",
    "\n",
    "    - This is the main table, broken into two files for Train (with TARGET) and Test (without TARGET).\n",
    "    - Static data for all applications. One row represents one loan in our data sample.\n",
    "\n",
    "- bureau.csv\n",
    "\n",
    "    - All client's previous credits provided by other financial institutions that were reported to Credit Bureau (for clients who have a loan in our sample).\n",
    "    - For every loan in our sample, there are as many rows as number of credits the client had in Credit Bureau before the application date.\n",
    "\n",
    "- bureau_balance.csv\n",
    "\n",
    "    - Monthly balances of previous credits in Credit Bureau.\n",
    "    - This table has one row for each month of history of every previous credit reported to Credit Bureau – i.e the table has (#loans in sample * # of relative previous credits * # of months where we have some history observable for the previous credits) rows.\n",
    "\n",
    "- pos_cash_balance.csv\n",
    "\n",
    "    - Monthly balance snapshots of previous POS (point of sales) and cash loans that the applicant had with Home Credit.\n",
    "    - This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credits * # of months in which we have some history observable for the previous credits) rows.\n",
    "\n",
    "- credit_card_balance.csv\n",
    "\n",
    "    - Monthly balance snapshots of previous credit cards that the applicant has with Home Credit.\n",
    "    - This table has one row for each month of history of every previous credit in Home Credit (consumer credit and cash loans) related to loans in our sample – i.e. the table has (#loans in sample * # of relative previous credit cards * # of months where we have some history observable for the previous credit card) rows.\n",
    "\n",
    "- previous_application.csv\n",
    "\n",
    "    - All previous applications for Home Credit loans of clients who have loans in our sample.\n",
    "    - There is one row for each previous application related to loans in our data sample.\n",
    "\n",
    "- installments_payments.csv\n",
    "\n",
    "    - Repayment history for the previously disbursed credits in Home Credit related to the loans in our sample.\n",
    "    - There is a) one row for every payment that was made plus b) one row each for missed payment.\n",
    "        - One row is equivalent to one payment of one installment OR one installment corresponding to one payment of one previous Home Credit credit related to loans in our sample.\n",
    "\n",
    "- home_credit_columns_description.csv\n",
    "\n",
    "    - This file contains descriptions for the columns in the various data files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5b7cb",
   "metadata": {},
   "source": [
    "![entity_relationship_diagram.png](../data/pictures/entity_relationship_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ea868",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa75daf6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%cd ..\n",
    "\n",
    "from models.risk_model import RiskModel\n",
    "from utils.exploratory_data_analysis_functions import (\n",
    "    create_comprehensive_bivariate_analysis,\n",
    "    print_feature_importance_summary,\n",
    "    analyze_mutual_information,\n",
    ")\n",
    "\n",
    "%cd notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088a050",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7109b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ae384",
   "metadata": {},
   "source": [
    "### Initialization of Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743dd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = Path(\"../data\")\n",
    "RANDOM_STATE = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44010812",
   "metadata": {},
   "source": [
    "## Risk Score Prediction Model Development\n",
    "\n",
    "This section develops a Risk Score Prediction Model that can be used with client questionnaire data to predict default risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c3cb6",
   "metadata": {},
   "source": [
    "### Importing Dataset into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778903b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "application_df = pd.read_parquet(path=DATA_DIRECTORY / \"application_train.parquet\")\n",
    "application_df.columns = application_df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de3fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values per column:\")\n",
    "application_df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ab869",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset shape: {application_df.shape}\")\n",
    "print(f\"Default rate: {application_df['target'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b67be6",
   "metadata": {},
   "source": [
    "### Wrangling, Feature Selection and Analysis\n",
    "\n",
    "Let's identify the most important features that can be easily collected from clients through a questionnaire AND exist in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaire_features = [\n",
    "    \"code_gender\",  # Gender of the client\n",
    "    \"flag_own_car\",  # Whether client owns a car\n",
    "    \"flag_own_realty\",  # Whether client owns house/flat\n",
    "    \"cnt_children\",  # Number of children\n",
    "    \"amt_income_total\",  # Total income\n",
    "    \"name_income_type\",  # Type of income (working, pensioner, etc.)\n",
    "    \"name_education_type\",  # Education level\n",
    "    \"name_family_status\",  # Family status (married, single, etc.)\n",
    "    \"name_housing_type\",  # Housing situation\n",
    "    \"days_birth\",  # Age (will convert to years)\n",
    "    \"days_employed\",  # Employment duration (will convert to years)\n",
    "    \"cnt_fam_members\",  # Number of family members\n",
    "    \"name_contract_type\",  # Type of loan contract\n",
    "    \"amt_credit\",  # Credit amount requested\n",
    "    \"amt_annuity\",  # Loan annuity amount\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68c21f",
   "metadata": {},
   "source": [
    "#### Creating more understandable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0528a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = (\n",
    "    application_df[questionnaire_features + [\"target\"]]\n",
    "    .assign(\n",
    "        age_years=lambda df: -df[\"days_birth\"] / 365,\n",
    "        years_employed=lambda df: np.where(\n",
    "            -df[\"days_employed\"] / 365 < 0,\n",
    "            0,  # we presume that negative values indicate that client has not worked at all\n",
    "            -df[\"days_employed\"] / 365,\n",
    "        ),\n",
    "    )\n",
    "    .drop(columns=[\"days_birth\", \"days_employed\"])\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"code_gender\": \"gender\",\n",
    "            \"flag_own_car\": \"owns_car\",\n",
    "            \"flag_own_realty\": \"owns_housing\",\n",
    "            \"cnt_children\": \"num_children\",\n",
    "            \"amt_income_total\": \"total_income\",\n",
    "            \"name_income_type\": \"income_type\",\n",
    "            \"name_education_type\": \"education_level\",\n",
    "            \"name_family_status\": \"family_status\",\n",
    "            \"name_housing_type\": \"housing_type\",\n",
    "            \"cnt_fam_members\": \"num_family_members\",\n",
    "            \"name_contract_type\": \"contract_type\",\n",
    "            \"amt_credit\": \"credit_amount\",\n",
    "            \"amt_annuity\": \"loan_annuity\",\n",
    "            \"target\": \"defaulted\",\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ec4a8",
   "metadata": {},
   "source": [
    "#### Impute missing values for amt_annuity and cnt_fam_members in model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.isnull().sum()[model_df.isnull().sum() > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9438b7",
   "metadata": {},
   "source": [
    "Due to very low number of missing values we will simply impute missing values with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd659cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df[\"loan_annuity\"] = model_df[\"loan_annuity\"].fillna(\n",
    "    model_df[\"loan_annuity\"].median()\n",
    ")\n",
    "model_df[\"num_family_members\"] = model_df[\"num_family_members\"].fillna(\n",
    "    model_df[\"num_family_members\"].median()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdfa11e",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e16c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = create_comprehensive_bivariate_analysis(\n",
    "    data=model_df,\n",
    "    numerical_features=model_df.drop(columns=\"defaulted\", errors=\"ignore\")\n",
    "    .select_dtypes(exclude=[\"object\"])\n",
    "    .columns,\n",
    "    categorical_features=model_df.drop(columns=\"defaulted\", errors=\"ignore\")\n",
    "    .select_dtypes(include=[\"object\"])\n",
    "    .columns,\n",
    "    target_col=\"defaulted\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a2772",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94dbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_groups = {\n",
    "    \"numerical\": [\n",
    "        \"age_years\",\n",
    "        \"years_employed\",\n",
    "        \"num_children\",\n",
    "        \"num_family_members\",\n",
    "        \"total_income\",\n",
    "        \"credit_amount\",\n",
    "        \"loan_annuity\",\n",
    "    ],\n",
    "    \"binary\": [\"gender\", \"owns_car\", \"owns_housing\", \"contract_type\"],\n",
    "    \"categorical\": [\"income_type\", \"education_level\", \"family_status\", \"housing_type\"],\n",
    "}\n",
    "\n",
    "binary_encoding = {\n",
    "    \"gender\": (\"M\", 1),\n",
    "    \"owns_car\": (\"Y\", 1),\n",
    "    \"owns_housing\": (\"Y\", 1),\n",
    "    \"contract_type\": (\"Cash loans\", 1),\n",
    "}\n",
    "\n",
    "mi_df, discretized_df = analyze_mutual_information(\n",
    "    df=model_df,\n",
    "    target_col=\"defaulted\",\n",
    "    feature_groups=feature_groups,\n",
    "    binary_encoding=binary_encoding,\n",
    "    n_bins=20,\n",
    "    balance_data=True,\n",
    "    figsize=(18, 16),\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ab6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_importance_summary(analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model = RiskModel(data_directory=DATA_DIRECTORY, random_state=RANDOM_STATE)\n",
    "print(\"Loading pre-trained model from assets...\")\n",
    "risk_model.load()\n",
    "\n",
    "print(\"\\nModel loaded successfully!\")\n",
    "print(f\"Total features: {len(risk_model.feature_names)}\")\n",
    "print(f\"Model is trained: {risk_model.is_trained}\")\n",
    "print(f\"SHAP explainer initialized: {risk_model.shap_explainer is not None}\")\n",
    "\n",
    "results = {\n",
    "    \"optimal_threshold\": risk_model.optimal_threshold,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af2f42e",
   "metadata": {},
   "source": [
    "#### Feature Importance Analysis\n",
    "\n",
    "Now let's create a comprehensive feature importance chart that matches what users see in the Streamlit application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0154fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = risk_model.plot_feature_importance(top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75d6c6",
   "metadata": {},
   "source": [
    "#### Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca872e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_df.drop(\"defaulted\", axis=1)\n",
    "y = model_df[\"defaulted\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "y_pred_proba = risk_model.pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_pred_proba >= risk_model.optimal_threshold).astype(int)\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_STATE)\n",
    "baseline.fit(X_train, y_train)\n",
    "baseline_pred = baseline.predict(X_test)\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"{'Metric':<20} {'Baseline':<12} {'Current Model':<15} {'Improvement'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "metrics = {\n",
    "    \"ROC-AUC\": (0.5, roc_auc_score(y_test, y_pred_proba)),\n",
    "    \"Accuracy\": (accuracy_score(y_test, baseline_pred), accuracy_score(y_test, y_pred)),\n",
    "}\n",
    "\n",
    "for metric, (base, current) in metrics.items():\n",
    "    improvement = ((current - base) / base * 100) if base > 0 else 0\n",
    "    print(f\"{metric:<20} {base:<12.4f} {current:<15.4f} {improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58baf78",
   "metadata": {},
   "source": [
    "#### Variance Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13becdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = abs(r2_score(y_test, y_pred_proba))\n",
    "print(f\"Model Variance Explained (R²): {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b5eb99",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28029b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, axes = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    ax=axes,\n",
    "    xticklabels=[\"No Default\", \"Default\"],\n",
    "    yticklabels=[\"No Default\", \"Default\"],\n",
    ")\n",
    "axes.set_title(\"Confusion Matrix (Counts)\", fontsize=14, weight=\"bold\")\n",
    "axes.set_ylabel(\"Actual\")\n",
    "axes.set_xlabel(\"Predicted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721dcae6",
   "metadata": {},
   "source": [
    "The model’s accuracy is fairly decent. Given the features it was trained on, it was quite difficult to improve the accuracy further. To enhance performance, we would need more informative features. Additionally, we could develop other models — not necessarily machine learning ones — and ensemble them to increase predictive power."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home-credit-default-risk-py3.12 (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
